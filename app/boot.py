# app/boot.py

"""
Run once at process start-up:
‚Ä¢ Walk through /app/data/persist looking for *.pdf
‚Ä¢ Skip any file already indexed
‚Ä¢ Ingest ‚Üí chunk ‚Üí embed ‚Üí store
"""

import asyncio
import logging
import time
from pathlib import Path
from datetime import datetime

from app.vector_store import new_persistent_store, persist_has_source
from app.ingestion import load_and_split

PERSIST_PDF_DIR = Path("/app/data/persist")
PERSIST_PDF_DIR.mkdir(parents=True, exist_ok=True)

log = logging.getLogger("boot")
log.setLevel(logging.INFO)

def _index_file(pdf_path: Path) -> None:
    log.info("üîÑ  indexing %s", pdf_path.name)
    start = time.perf_counter()
    store = new_persistent_store()
    chunks = load_and_split(str(pdf_path))
    if not chunks:
        log.warning("‚ö†Ô∏è  no text extracted from %s ‚Äì skipping", pdf_path.name)
        return
    for c in chunks:
        c.metadata["source"] = pdf_path.name
        c.metadata["indexed_at"] = datetime.utcnow().isoformat()
    try:
        store.add_documents(chunks)
        store.persist()
        dur = time.perf_counter() - start
        log.info("‚úÖ  stored %d chunks for %s in %.2fs", len(chunks), pdf_path.name, dur)
    except ValueError as exc:
        log.error("‚ùå  failed to store embeddings for %s: %s", pdf_path.name, exc)
    finally:
        del store

async def run() -> None:
    pdfs = sorted(PERSIST_PDF_DIR.glob("*.pdf"))
    if not pdfs:
        log.info("üìÇ  no PDFs found ‚Äì skipping indexing")
        return

    async def worker(pdf: Path) -> None:
        if persist_has_source(pdf.name):
            log.debug("‚Ü™Ô∏é  already indexed: %s", pdf.name)
            return
        try:
            await asyncio.to_thread(_index_file, pdf)
        except Exception:
            log.exception("‚ùå  failed to index %s", pdf.name)

    await asyncio.gather(*(worker(pdf) for pdf in pdfs))

if __name__ == "__main__":
    asyncio.run(run())
